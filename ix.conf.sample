# ix.conf
# configuration file for IX
#
# This file defines the configuration for IX data center OS. You should
# carefully update all fields in accordence with your local configuration
# before running IX for the first time.

###############################################################################
# Network Parameters
###############################################################################

## host_addr : CIDR IP address and netmask that will be assigned to
##      the adapter once it comes up.
host_addr="10.10.66.3/24"

# gateway_addr : default gateway IP address
gateway_addr="10.10.66.1"

## port : port(s) that will be bound to the application by the
##      kernel when launching IX.
##      You can specify multiple entries, e.g. 'port=[X, Y, Z]'
##      adding admitted ports here when using more cores
port=[1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241]

###############################################################################
# Hardware parameters
###############################################################################

## devices : Specifies the PCI device ID of the adapter to bind IX with.
##      Should be an Intel compatible NIC (e.g. 82599, X520, X540, etc)..
##      See the Docs to see which adapters are currently supported.
##      Format is a list dddd:bb:ss.ff,... d - domain, b = bus,
##      s = slot, f = function. Usually, `lspci | grep Ethernet` allows to see
##      available Ethernet controllers. Similarly, `lspci | grep Non-Volatile` 
##	    allows to see available NVMe SSD controllers. 
##      You can specify multiple entries, e.g. 'devices=["X","Y","Z"]'
##      Updates:
##      1. Now support Broadcom NICs (e.g. BCM58800 etc.)
##      2. Now support multiple NVMes SSDs
##      3. Now support namespace size configuration (only at client-end)
devices="0008:01:00.0"
# nvme_devices="0000:01:00.0"
nvme_devices=["0000:01:00.0", "0001:01:00.0", "0006:01:00.0", "0007:01:00.0"]
# ns_size=["0xE8E0DB6000"]

###############################################################################
# ReFlex I/O scheduler parameters
###############################################################################
# nvme_device_model: "sample.devmodel" is a sample config file for a device model
# 					     which specifies read/write costs and token limits for 
# 					     tail latency SLOs; values are device-specific
# 					     You should follow instructions in this file to modify 
# 					     values corresponding to the performance of your SSD.
# 					     Either modify sample.devmodel directly or copy to a 
# 					     different file and specify file name here.
# 					 "default" for no token limits
# 					 "fake" models ultra low latency device since we don't
# 					     submit I/Os to real device, just generate fake I/O 
# 					     completion events (can be useful for perf debugging)
#
# scheduler: 		 "on" (by default) 
# 					 "off" means I/O submitted directly to flash, 
# 					     no SW queueing, no QoS scheduling 
#                    turn off this in the client			 
nvme_device_model="sample.devmodel" 
scheduler="on"

## cpu : Indicates which CPU process unit(s) (P) this IX instance
##      should be bound to.
##      WARNING: If this setting defines multiple nodes, make sure they ar
##      part of the same NUMA socket. On most architectures, the IDs of
##      processing units on the same socket are interleaved.
##      Usually `lstopo` allows to see NUMA nodes topology
##      You can specify multiple entries, e.g. 'nodes=["X","Y","Z"]'
# cpu=[0, 1, 2, 3, 4, 5, 6, 7]
# cpu=[0]
# cpu=[3]
cpu=[0, 1]
# cpu=[0, 1, 2]
# cpu=[0, 1, 2, 3]
# cpu=[0, 1, 2, 3, 4]
# cpu=[0, 1, 2, 3, 4, 5]
# cpu=[0, 1, 2, 3, 4, 5, 6]
# cpu=[0, 1, 2, 3, 4, 5, 6, 7]

## mem_channel  : how many memory channels will be used
##  Default: -1
mem_channel=1


## batch : Specifies maximum batch size of received packets to process.
##      Default: 64.
batch=64

## loader_path : kernel loader to use with IX module:
##
# loader_path="/lib64/ld-linux-x86-64.so.2"
loader_path="/lib/ld-linux-aarch64.so.1"

###############################################################################
# Optional parameters
###############################################################################

## arp: Allows you to manually add static arp entries in the interface arp table
#
#arp=(
#  {
#    ip : "192.168.1.2"
#    mac : "aa:aa:aa:aa:aa:aa"
#  },
#  {
#    ip : "192.168.1.3"
#    mac : "bb:bb:bb:bb:bb:bb"
#  }
#)


## fdir : Static flow director rules to be added to NIC
#		  Use this to steer traffic to particular cores when multi-core ReFlex.
#         Queue number corresponds to CPU core id
#
# fdir=(
#     {
#         dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1234
#         queue : 0
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1235
#         queue : 1
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1236
#         queue : 2
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1237
#         queue : 3
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1238
#         queue : 4
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1239
#         queue : 5
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1240
#         queue : 6
#     },
#     {
# 	      dst_ip : "10.10.66.3"
#         src_ip : "10.10.66.2"
#         dst_port : 1241
#         queue : 7
#     }
#     # add more entries here and changing the dst_port and queue accordingly
# )
